{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vikbol112/sd-webui-faceswaplab/blob/main/Copy_of_AudioSR_Colab_Fork.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bYuiV2rlDizI"
      },
      "source": [
        "# **AudioSR-Colab-Fork v0.6**\n",
        "\n",
        "\n",
        "\n",
        "Colab adaptation of AudioSR, with modifications by Sweyei & jarredou.\n",
        "\n",
        "- v0.6 (Latest)\n",
        "\n",
        "Fixed: Dependency conflicts with transformers, sentence-transformers, and audiosr, ensuring proper compatibility.\n",
        "Fixed: pip resolver issues by enforcing stricter package versions to prevent installation failures.\n",
        "Fixed: CUDA compatibility issues, optimizing model performance for GPU acceleration.\n",
        "Fixed: Hugging Face resume_download deprecation warning.\n",
        "Fixed: timm.models.layers import warning (updated to timm.layers).\n",
        "Improved: Model loading efficiency for faster initialization.\n",
        "Improved: Audio processing stability, reducing potential errors during inference.\n",
        "\n",
        "- v0.5\n",
        "\n",
        "Resampled input audio based on input_cutoff instead of lowpass filtering.\n",
        "Normalized each processed chunk to the same LUFS level as the input chunk (fixes volume drop issue).\n",
        "\n",
        "- v0.4\n",
        "\n",
        "Code rework: inference.py created for local CLI usage.\n",
        "\n",
        "- v0.3\n",
        "\n",
        "Added: Multiband ensemble option to merge original audio below the cutoff frequency with generated audio above.\n",
        "Fixed: Non-WAV input error when saving the final audio.\n",
        "\n",
        "- v0.2\n",
        "\n",
        "Added: Chunking feature to process audio of any length.\n",
        "Added: Stereo handling‚Äîeach stereo channel is processed independently (dual mono) and reconstructed as stereo audio.\n",
        "Added: Overlap feature to smooth chunk transitions (avoid high values as AudioSR is not fully phase-accurate, which may cause phase cancellations).\n",
        "\n",
        "- Modifications & Changes by Sweyei & [jarredou](https://https://github.com/jarredou/)\n",
        "\n",
        "Original work [AudioSR: Versatile Audio Super-resolution at Scale](https://github.com/haoheliu/versatile_audio_super_resolution) by Haohe Liu, Ke Chen, Qiao Tian, Wenwu Wang, Mark D. Plumbley\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7t23Tz5XIcON"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "\n",
        "# Clone repo if it doesn't exist\n",
        "if not os.path.exists(\"versatile_audio_super_resolution\"):\n",
        "    !git clone https://github.com/haoheliu/versatile_audio_super_resolution.git\n",
        "%cd versatile_audio_super_resolution\n",
        "\n",
        "# Install dependencies\n",
        "!pip install -r requirements.txt\n",
        "!pip install --upgrade pip\n",
        "!pip uninstall -y transformers sentence-transformers audiosr\n",
        "!pip install transformers==4.30.2 audiosr==0.0.7 --no-deps\n",
        "!pip install cog huggingface_hub==0.29.2 unidecode phonemizer einops torchlibrosa ftfy timm librosa pyloudnorm soundfile progressbar\n",
        "\n",
        "# Download inference script, overwrite if it exists\n",
        "!wget -O inference.py https://raw.githubusercontent.com/jarredou/AudioSR-Colab-Fork/main/inference.py\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gWUd27QECiLw"
      },
      "source": [
        "### **IMPORTANT NOTE**\n",
        "\n",
        "#### If the inference cell crashes, restart the runtime (do not disconnect, just restart it), else it will cause memory errors !\n",
        "\n",
        "*If you're are doing multiple runs, think also to restart the runtime every 4 or 5 files to clean up memory*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WfjZ_Q0OIepR"
      },
      "outputs": [],
      "source": [
        "#@markdown # **Change Directory & Import Dependencies**\n",
        "%cd /content/versatile_audio_super_resolution\n",
        "\n",
        "import os\n",
        "import torch\n",
        "import warnings\n",
        "\n",
        "# Suppress warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Set precision for better performance\n",
        "torch.set_float32_matmul_precision(\"high\")\n",
        "\n",
        "# Select device: Use GPU if available, otherwise fallback to CPU\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"üöÄ Using device: {device.upper()}\")\n",
        "\n",
        "#@markdown # **File Paths**\n",
        "input_file_path = \"/content/drive/MyDrive/AudioSR/jotc_remaster.mp3\" #@param {type:\"string\"}\n",
        "output_folder = \"/content/drive/MyDrive/output\" #@param {type:\"string\"}\n",
        "\n",
        "# Check if input file exists\n",
        "if not os.path.exists(input_file_path):\n",
        "    raise FileNotFoundError(f\"‚ùå Error: Input file '{input_file_path}' not found!\")\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown # **Inference Parameters**\n",
        "ddim_steps = 20 #@param {type:\"slider\", min:20, max:200, step:10}\n",
        "overlap = 0.04 #@param {type:\"slider\", min:0, max:0.96, step:0.04}\n",
        "guidance_scale = 3.5 #@param {type:\"slider\", min:1, max:15, step:0.5}\n",
        "seed = 0 #@param {type:\"integer\"}\n",
        "chunk_size = 10.24 #@param [5.12, 10.24, 20.48] {type:\"raw\"}\n",
        "multiband_ensemble = True #@param {type:\"boolean\"}\n",
        "input_cutoff = \"14000\" #@param [20000, 19000, 18000, 17000, 16000, 14000, 13000, 12000, 11000, 10000, 9000, 8000, 7000, 6000, 5000, 4000, 3000, 2000]\n",
        "input_cutoff = int(input_cutoff)\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown # **Check GPU Status**\n",
        "if device == \"cuda\":\n",
        "    print(\"üöÄ CUDA Available:\", torch.cuda.is_available())\n",
        "    print(\"üñ•Ô∏è Current Device:\", torch.cuda.current_device())\n",
        "    print(\"üîã Memory Allocated:\", torch.cuda.memory_allocated() / 1e9, \"GB\")\n",
        "    print(\"üíæ Memory Reserved:\", torch.cuda.memory_reserved() / 1e9, \"GB\")\n",
        "else:\n",
        "    print(\"‚ö° Running on CPU (CUDA not available)\")\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown # **Run Inference**\n",
        "!python inference.py --input \"{input_file_path}\" \\\n",
        "                     --output \"{output_folder}\" \\\n",
        "                     --ddim_steps {ddim_steps} \\\n",
        "                     --guidance_scale {guidance_scale} \\\n",
        "                     --seed {seed} \\\n",
        "                     --chunk_size {chunk_size} \\\n",
        "                     --overlap {overlap} \\\n",
        "                     --multiband_ensemble {str(multiband_ensemble).lower()} \\\n",
        "                     --input_cutoff {input_cutoff} \\\n",
        "                     --device {device}"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Nytt avsnitt"
      ],
      "metadata": {
        "id": "Hrer3WK3lwWv"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}